<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>ceshi</title>
    <url>/2020/07/18/ceshi/</url>
    <content><![CDATA[]]></content>
  </entry>
  <entry>
    <title>happens-before和as-if-serial语义</title>
    <url>/2020/07/21/happens-before%E5%92%8Cas-if-serial%E8%AF%AD%E4%B9%89/</url>
    <content><![CDATA[<h2 id="happends-before"><a href="#happends-before" class="headerlink" title="happends-before"></a>happends-before</h2><p>前面文章我们简单说了下重排序，重排序带来的最大的问题就是多线程环境下程序运行结果不可控，和我们期待不一样，这个时候就引入了happend-before规则，也就是说happend-before是用来保证多线程环境下程序结果的正确性.</p>
<h3 id="happens-before定义"><a href="#happens-before定义" class="headerlink" title="happens-before定义"></a>happens-before定义</h3><p>在《JSR-133:Java Memory Model and Thread Specification》中是这样定义happens-before规则：</p>
<ul>
<li>如果一个操作happens-before另一个操作，那么<strong>第一个操作的执行结果将对第二个操作可见</strong>，而且第一个操作的执行顺序排在第二个操作之前。</li>
<li>两个操作之间存在happens-before关系，并不意味着Java平台的具体实现必须要按照 happens-before关系指定的顺序来执行。如果重排序之后的执行结果，与按happens-before关系来执行的结果一致，那么这种重排序并不非法，也就是说，JMM允许这种重排序。</li>
</ul>
<a id="more"></a>
<p>咋看之下这两条规则是矛盾的，其实核心点在于<strong>第一个操作的结果对第一个操作可见</strong>。</p>
<p>第一点是从JMM角度出发，JMM承诺给程序员如果A happends-before B，那么A的执行结果B是看的到的，并且A在B之前执行<br>第二点则是从编译器和处理器重排序角度出发，重排序的原则就在于只要我保证程序运行结果是正确的，我就会进行重排序优化，而这个结果正确如何保证了，也就是<strong>如果A happends-before B，那么A的执行结果B是看的到的(结果正确)，但我不保证A在B之前执行(我还是会进行重排序优化，前提是结果正确)。</strong></p>
<p>其实我并没找到很好的例子来佐证第二点，但是要传递的思想就是程序员追求程序结果正确，而不关心内部处理器如何优化重排序。</p>
<h3 id="hanppens-before规则"><a href="#hanppens-before规则" class="headerlink" title="hanppens-before规则"></a>hanppens-before规则</h3><p>1：程序顺序规则：一个线程中的每个操作，happens-before于该线程中的任意后续操作。<br>2：监视器锁规则：对一个锁的解锁，happens-before于随后对这个锁的加锁。<br>3：volatile变量规则：对一个volatile域的写，happens-before于任意后续对这个volatile域的读。<br>4：传递性：如果A happens-before B，且B happens-before C，那么A happens-before C。<br>5：start()规则：如果线程A执行操作ThreadB.start()（启动线程B），那么A线程的 ThreadB.start()操作happens-before于线程B中的任意操作。<br>6：join()规则：如果线程A执行操作ThreadB.join()并成功返回，那么线程B中的任意操作 happens-before于线程A从ThreadB.join()操作成功返回。</p>
<h2 id="as-if-serial语义"><a href="#as-if-serial语义" class="headerlink" title="as-if-serial语义"></a>as-if-serial语义</h2><p>相较于happend-before，as-if-serial相对简单：不管怎么重排序（编译器和处理器为了提高并行度），（单线程）程序的执行结果不能被改变。编译器、runtime和处理器都必须遵守as-if-serial语义，为了遵守as-if-serial语义，编译器和处理器不会对存在数据依赖关系的操作做重排序，因为这种重排序会改变执行结果。但是，如果操作之间不存在数据依赖关系，这些操作就可能被编译器和处理器重排序</p>
<p>as-if-serial带给编写单线程程序的程序员的幻觉：我的程序是按照顺序执行，虽然有可能处理器做了优化重排序,但是最后结果是正确的。</p>
]]></content>
      <categories>
        <category>详解java并发</category>
      </categories>
      <tags>
        <tag>java并发</tag>
      </tags>
  </entry>
  <entry>
    <title>Hello World</title>
    <url>/2020/07/18/hello-world/</url>
    <content><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p>
<a id="more"></a>

<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/one-command-deployment.html" target="_blank" rel="noopener">Deployment</a></p>
]]></content>
  </entry>
  <entry>
    <title>java内存模型之volatile</title>
    <url>/2020/07/21/java%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B%E4%B9%8Bvolatile/</url>
    <content><![CDATA[<h2 id="缓存一致性"><a href="#缓存一致性" class="headerlink" title="缓存一致性"></a>缓存一致性</h2><p>看向这张图：<img src="https://upload-images.jianshu.io/upload_images/18971971-b5d0aa41f5c0ced0.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt><br>很显然当线程A,B同时对一个共享变量操作时(先操作共享变量的副本，然后再把副本刷新到主内存中)，会出现<strong>缓存一致性</strong>问题，最简单的例子就是</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">i++;</span><br></pre></td></tr></table></figure>
<p>不同线程对各自内存中的i执行i++操作，但是回写到主内存时会覆盖其它线程的操作结果，最终结果和预想不一致，这个现象称为<strong>缓存一致性</strong>，解决它主要两种方案</p>
<ul>
<li>通过在总线加LOCK#锁的方式(简单理解成某一时刻只能有一个线程操作某个共享变量更多总线锁内容可以参考#<a href="https://blog.csdn.net/qq_35642036/article/details/82801708" target="_blank" rel="noopener">总线锁</a></li>
<li>通过缓存一致性协议</li>
</ul>
<p>很明显第一种方案–总线锁采用一种独占的方式来实现的，即总线加LOCK#锁的话，只能有一个CPU能够运行，其他CPU都得阻塞，效率堪忧，第二种方案–缓存一致性协议（MESI协议）它确保每个缓存中使用的共享变量是一致的。其核心思想如下：<strong>当某个CPU在写数据时，如果发现操作的变量是共享变量，则会通知其他CPU告知该变量的缓存行是无效的，因此其他CPU在读取该变量时，发现其无效会重新从主存中加载数据。</strong></p>
<a id="more"></a>
<h2 id="volatile"><a href="#volatile" class="headerlink" title="volatile"></a>volatile</h2><ul>
<li>可见性：被volatile修饰的共享变量一旦被一个线程修改，会立刻同步到主内存中，并且别的线程在使用这个共享变量时会从主内存中读取，而不是本地内存</li>
<li>有序性：禁止指令重排序(JVM底层volatile是采用“内存屏障”来实现的)</li>
<li>只保证单次读写的原子性，不保证复合操作的原子性，也就是i++，即使i使用了volatile关键字修饰，也不是一个原子操作</li>
</ul>
<h3 id="volatile原理"><a href="#volatile原理" class="headerlink" title="volatile原理"></a>volatile原理</h3><h4 id="lock指令"><a href="#lock指令" class="headerlink" title="lock指令"></a>lock指令</h4><p>当修改一个volatile修饰的变量，在写回到主内存中会多出现一行汇编命令：<br>lock addl $0×0,(%esp)<br>这一行命令作用有三:</p>
<ul>
<li>锁总线，其它CPU对内存的读写请求都会被阻塞，直到锁释放，不过实际后来的处理器都采用锁缓存替代锁总线，因为锁总线的开销比较大，锁总线期间其他CPU没法访问内存</li>
<li>lock后的写操作会回写已修改的数据，同时让其它CPU相关缓存行失效，从而重新从主存中加载最新的数据</li>
<li>不是内存屏障却能完成类似内存屏障的功能，阻止屏障两遍的指令重排序<br>更多lock指令详解可以参考# <a href="https://www.cnblogs.com/badboys/p/12695183.html" target="_blank" rel="noopener">volatile与lock前缀指令</a></li>
</ul>
<p>那么<strong>每个处理器通过嗅探在总线上传播的数据来检查自己的缓存值是不是过期了，如果处理器发现自己缓存行对应的内存地址呗修改，就会将当前处理器的缓存行设置无效状态，会重新从系统内存中把数据库读到处理器缓存中。</strong></p>
<h4 id="volatile重排序规则"><a href="#volatile重排序规则" class="headerlink" title="volatile重排序规则"></a>volatile重排序规则</h4><table>
<thead>
<tr>
<th align="center"></th>
<th align="center">第二个操作</th>
<th align="center"></th>
<th align="center"></th>
</tr>
</thead>
<tbody><tr>
<td align="center">第一个操作</td>
<td align="center">普通读写</td>
<td align="center">volatile读</td>
<td align="center">volatile写</td>
</tr>
<tr>
<td align="center">普通读写</td>
<td align="center"></td>
<td align="center"></td>
<td align="center">NO</td>
</tr>
<tr>
<td align="center">volatiel读</td>
<td align="center">NO</td>
<td align="center">NO</td>
<td align="center">NO</td>
</tr>
<tr>
<td align="center">volatiel写</td>
<td align="center"></td>
<td align="center">No</td>
<td align="center">NO</td>
</tr>
<tr>
<td align="center">总结：</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr>
<td align="center">- 当第二个操作是volatile写时，不管第一个操作是什么，都不能重排序。这个规则确保 volatile写之前的操作不会被编译器重排序到volatile写之后</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr>
<td align="center">- 当第一个操作是volatile读时，不管第二个操作是什么，都不能重排序。这个规则确保 volatile读之后的操作不会被编译器重排序到volatile读之前</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr>
<td align="center">- 当第一个操作是volatile写，第二个操作是volatile读时，不能重排序。</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr>
<td align="center">#### 内存屏障</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr>
<td align="center">- 在每个volatile写操作的前面插入一个StoreStore屏障</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr>
<td align="center">- 在每个volatile写操作的后面插入一个StoreLoad屏障</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr>
<td align="center">- 在每个volatile读操作的后面插入一个LoadLoad屏障</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr>
<td align="center">- 在每个volatile读操作的后面插入一个LoadStore屏障</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr>
<td align="center">这是JMM在保守策略下指令序列生成，如下图：</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr>
<td align="center"><img src="https://upload-images.jianshu.io/upload_images/18971971-bfe00fdad205f137.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr>
<td align="center">编译器则会在字节码做一些优化，如下图：</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr>
<td align="center"><img src="https://upload-images.jianshu.io/upload_images/18971971-ccab4d06f1d17716.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
</tbody></table>
<p>在优化这一阶段，不同处理器也有各自不同的松紧度，比如x86处理器，只会有最后的StoreLoad屏障(我们在前面文章也说过StoreLoad就是另外三个屏障功能的综合)，如下图：<br><img src="https://upload-images.jianshu.io/upload_images/18971971-b6c61128912b6f3c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt></p>
]]></content>
      <categories>
        <category>详解java并发</category>
      </categories>
      <tags>
        <tag>java并发</tag>
      </tags>
  </entry>
  <entry>
    <title>为什么 wait ，notify方法定义在 Object 类里面，而不是Thread中</title>
    <url>/2020/07/21/%E4%B8%BA%E4%BB%80%E4%B9%88%20wait%20%EF%BC%8Cnotify%E6%96%B9%E6%B3%95%E5%AE%9A%E4%B9%89%E5%9C%A8%20Object%20%E7%B1%BB%E9%87%8C%E9%9D%A2%EF%BC%8C%E8%80%8C%E4%B8%8D%E6%98%AFThread%E4%B8%AD/</url>
    <content><![CDATA[<p>为什么 wait ，notify方法定义在 Object 类里面，而不是Thread中。</p>
<ul>
<li>每个对象都可以上锁，所以在所有类的超类Object里面定义而不是Thread定义。</li>
<li>java的锁是基于monitor(监视器)的概念，而所有对象都是有监视器的。</li>
</ul>
<a id="more"></a>
<p>其实来讲，想要一个线程能够在某个对象上面拿到锁，释放锁，锁等待一系列操作，也就是在monitor上面有这些操作，只需要两个参数即可，线程和某个对象，那么完全可以新建一个utils类，定义一个方法wait(Thread thread,Object object)，但反过来讲，这不就是当前java的设计吗？Object是所有类的超类，wait方法定义在Object中。</p>
<p>还有两种观点也有道理:</p>
<ul>
<li>wait 和 notify 不仅仅是普通方法或同步工具，更重要的是它们是 Java 中两个线程之间的通信机制。对语言设计者而言, 如果不能通过 Java 关键字(例如 synchronized)实现通信此机制，同时又要确保这个机制对每个对象可用, 那么 Object 类则是的合理的声明位置。记住同步和等待通知是两个不同的领域，不要把它们看成是相同的或相关的。同步是提供互斥并确保 Java 类的线程安全，而 wait 和 notify 是两个线程之间的通信机制</li>
<li>在 Java 中，为了进入代码的临界区，线程需要锁定并等待锁，他们不知道哪些线程持有锁，而只是知道锁被某个线程持有， 并且需要等待以取得锁, 而不是去了解哪个线程在同步块内，并请求它们释放锁</li>
</ul>
]]></content>
      <categories>
        <category>每日一题</category>
      </categories>
  </entry>
  <entry>
    <title>java内存模型之重排序</title>
    <url>/2020/07/21/%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8BJMM/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>在了解重排序之前，你还需要知道一些基础概念知识，我在这罗列出来。</p>
<h3 id="数据依赖性"><a href="#数据依赖性" class="headerlink" title="数据依赖性"></a>数据依赖性</h3><p>如果两个操作同时访问同一个变量，只要其中有一个操作是写操作，那么这两个操作之间就存在数据依赖性。具体示例见下表:</p>
<table>
<thead>
<tr>
<th align="center">操作顺序</th>
<th align="center">代码</th>
<th align="center">解释说明</th>
</tr>
</thead>
<tbody><tr>
<td align="center">先写a再读a</td>
<td align="center">a=1;b=a</td>
<td align="center">先写a为1，再读取a的值赋给b</td>
</tr>
<tr>
<td align="center">先写a再写a</td>
<td align="center">a=1;a=2</td>
<td align="center">先写a为1，再写a为2</td>
</tr>
<tr>
<td align="center">先读b再写b</td>
<td align="center">a=b;b=1</td>
<td align="center">先写a为b，再写b为1</td>
</tr>
</tbody></table>
<p>很明显，我们可以得知上面顺序一旦交换，最后结果是有问题的，所以<strong>在重排序中，会遵守数据依赖性，重排序不会改变存在数据依赖性的两个操作的执行顺序</strong>。<br>需要注意的是<strong>数据依赖性是针对单线程</strong>而言的，多线程是不存在数据依赖性这一说，也就是重排序在多线程这一块并不遵守这个规定。</p>
<a id="more"></a>
<h3 id="java内存模型抽象概念"><a href="#java内存模型抽象概念" class="headerlink" title="java内存模型抽象概念"></a>java内存模型抽象概念</h3><p><img src="https://upload-images.jianshu.io/upload_images/18971971-f4b4c8a738c2a20f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="jmm内存模型抽象图"><br>java语言中，堆内存是多线程共享，所以图中的<strong>共享变量指的是实例域，静态域，数组元素，而不是局部变量，方法定义参数，异常处理参数</strong>。</p>
<h3 id="内存一致性"><a href="#内存一致性" class="headerlink" title="内存一致性"></a>内存一致性</h3><p>内存一致性说的是共享内存多核处理器访存序的问题，进程对某一个内存地址(和分布式的同一数据多副本的一致性有所区别)的访问序在多核下暴露出的问题，单核乱序执行重新排列无关的指令在多核系统中可能出现问题。也就是程序中 Load Store 的(ISA)顺序(冯诺依曼架构下看可以看做内存操作请求的顺序)和Load Store实际执行完成的顺序可能相同、可能不同(这取决于微体系结构的实现)，在多核情况下，程序的正确性可能出问题。有各种一致性模型来表达各种程度的相同不同，相应的有软、硬件机制来确保多核处理器上程序的正确运行</p>
<h3 id="缓存一致性"><a href="#缓存一致性" class="headerlink" title="缓存一致性"></a>缓存一致性</h3><p>//TODO</p>
<h3 id="内存屏障"><a href="#内存屏障" class="headerlink" title="内存屏障"></a>内存屏障</h3><table>
<thead>
<tr>
<th align="center">屏障类型</th>
<th align="center">示例</th>
<th align="center">解释说明</th>
</tr>
</thead>
<tbody><tr>
<td align="center">LoadLoad Barriers</td>
<td align="center">Load1;LoadLoad;Load2</td>
<td align="center">确保Load1数据的装载先于Load2及所有后续装载指令的装载</td>
</tr>
<tr>
<td align="center">StoreStore Barriers</td>
<td align="center">Stroe1;StoreStore;Store2</td>
<td align="center">确保Store1数据对其它处理器可见(刷新到内存)先于Store2及所有后续存储指令的存储</td>
</tr>
<tr>
<td align="center">LoadStore Barriers</td>
<td align="center">Load1;LoadStore;Store2</td>
<td align="center">确保Load1装载数据先于Store2及所有后续的储存指令刷新到内存</td>
</tr>
<tr>
<td align="center">StoreLoad Barriers</td>
<td align="center">Stroe1;StoreLoad;Load2</td>
<td align="center">确保Strore1数据对其它处理器可见(刷新到内存),先于Load2及所有后续存储指令的存储</td>
</tr>
</tbody></table>
<p>StoreLoad Barriers是一个“全能型”的屏障，它同时具有其他3个屏障的效果。现代的多处理器大多支持该屏障（其他类型的屏障不一定被所有处理器支持）。执行该屏障开销会很昂贵，因为当前处理器通常要把写缓冲区中的数据全部刷新到内存中（Buffer Fully Flush）。</p>
<h2 id="源码到指令的重排序"><a href="#源码到指令的重排序" class="headerlink" title="源码到指令的重排序"></a>源码到指令的重排序</h2><p><strong>编译器和处理器会对指令来做重排序，是为了提高性能。</strong><br>重排序分为以下三类：</p>
<ul>
<li><strong>编译器优化的重排序</strong>。编译器在不改变单线程程序语义的前提下(也就是不改变单线程运行结果,其实这也可以用数据依赖性来解释)，可以重新安排语句的执行顺序</li>
<li><strong>处理器指令级并行的重排序</strong>。现代处理器采用了指令级并行技术（Instruction-Level Parallelism，ILP）来将多条指令重叠执行。如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序</li>
<li><strong>内存系统的重排序</strong>。由于处理器使用缓存和读/写缓冲区，这使得加载和存储操作看上去可能是在乱序执行</li>
</ul>
<p><img src="https://upload-images.jianshu.io/upload_images/18971971-0cfc57f9372eca97.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="源码到指令之间的重排序"><br>对于<strong>编译器</strong>，JMM的编译器重排序规则会<strong>禁止特定类型的编译器重排序</strong>（不是所有的编译器重排序都要禁止）。<br>对于<strong>处理器重排序</strong>，JMM的处理器重排序规则会要求Java编译器在生成指令序列时，<strong>插入特定类型的内存屏障</strong>（Memory Barriers，Intel称之为 Memory Fence）指令，通过内存屏障指令来禁止特定类型的处理器重排序。</p>
<h2 id="重排序带来的问题"><a href="#重排序带来的问题" class="headerlink" title="重排序带来的问题"></a>重排序带来的问题</h2><table>
<thead>
<tr>
<th align="center"></th>
<th align="center">程序1</th>
<th align="center">程序2</th>
</tr>
</thead>
<tbody><tr>
<td align="center">代码</td>
<td align="center">a=1;//A1<br>x=b;//A2</td>
<td align="center">b=2;//B1<br>y=a;//B2</td>
</tr>
<tr>
<td align="center">结果</td>
<td align="center">有可能错误的结果 x=y=0</td>
<td align="center"></td>
</tr>
</tbody></table>
<p>如下图:<img src="https://upload-images.jianshu.io/upload_images/18971971-02b26121efb878ed.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="重排序带来的问题"><br>这里处理器A和处理器B可以同时把共享变量写入自己的写缓冲区（A1，B1），然后从内存中读取另一个共享变量（A2，B2），最后才把自己写缓存区中保存的脏数据刷新到内存中（A3， B3）。当以这种时序执行时，程序就可以得到x=y=0的结果</p>
<p>这段代码也可以让你更清晰的认识到重排序带来的问题</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">class ReorderExample &#123;</span><br><span class="line">    int a &#x3D; 0;</span><br><span class="line">    boolean flag &#x3D; false;</span><br><span class="line"></span><br><span class="line">    public void writer() &#123;</span><br><span class="line">        a &#x3D; 1; &#x2F;&#x2F; 1</span><br><span class="line">        flag &#x3D; true; &#x2F;&#x2F; 2</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    Public void reader() &#123;</span><br><span class="line">        if (flag) &#123; &#x2F;&#x2F; 3</span><br><span class="line">            int i &#x3D; a * a; &#x2F;&#x2F; 4</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这段代码在多线程运行环境下可能的时序图有以下:<br><img src="https://upload-images.jianshu.io/upload_images/18971971-8956f30f35f55995.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="程序执行时序图1"><br><img src="https://upload-images.jianshu.io/upload_images/18971971-464e0086ea0914d4.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="程序执行时序图2"></p>
<p>通过这两张图我想已经很清晰的向你展示了重排序在多线程环境下给程序带来的不可控的结果,需要再次重申一次的是<strong>单线程下操作之间存在数据依赖性，不会重排序，但是多线程下，比如线程A的flag = true和线程B的if(flag) 并不存在数据依赖性</strong>,所以重排序在多线程下会发现，最后带来的就是程序结果和预期的不一样。</p>
]]></content>
      <categories>
        <category>详解java并发</category>
      </categories>
      <tags>
        <tag>java并发</tag>
      </tags>
  </entry>
</search>
