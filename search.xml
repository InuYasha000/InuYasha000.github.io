<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>ceshi</title>
    <url>/2020/07/18/ceshi/</url>
    <content><![CDATA[]]></content>
  </entry>
  <entry>
    <title>happens-before和as-if-serial语义</title>
    <url>/2020/07/21/happens-before%E5%92%8Cas-if-serial%E8%AF%AD%E4%B9%89/</url>
    <content><![CDATA[<h2 id="happends-before"><a href="#happends-before" class="headerlink" title="happends-before"></a>happends-before</h2><p>前面文章我们简单说了下重排序，重排序带来的最大的问题就是多线程环境下程序运行结果不可控，和我们期待不一样，这个时候就引入了happend-before规则，也就是说happend-before是用来保证多线程环境下程序结果的正确性.</p>
<h3 id="happens-before定义"><a href="#happens-before定义" class="headerlink" title="happens-before定义"></a>happens-before定义</h3><p>在《JSR-133:Java Memory Model and Thread Specification》中是这样定义happens-before规则：</p>
<ul>
<li>如果一个操作happens-before另一个操作，那么<strong>第一个操作的执行结果将对第二个操作可见</strong>，而且第一个操作的执行顺序排在第二个操作之前。</li>
<li>两个操作之间存在happens-before关系，并不意味着Java平台的具体实现必须要按照 happens-before关系指定的顺序来执行。如果重排序之后的执行结果，与按happens-before关系来执行的结果一致，那么这种重排序并不非法，也就是说，JMM允许这种重排序。</li>
</ul>
<a id="more"></a>
<p>咋看之下这两条规则是矛盾的，其实核心点在于<strong>第一个操作的结果对第一个操作可见</strong>。</p>
<p>第一点是从JMM角度出发，JMM承诺给程序员如果A happends-before B，那么A的执行结果B是看的到的，并且A在B之前执行<br>第二点则是从编译器和处理器重排序角度出发，重排序的原则就在于只要我保证程序运行结果是正确的，我就会进行重排序优化，而这个结果正确如何保证了，也就是<strong>如果A happends-before B，那么A的执行结果B是看的到的(结果正确)，但我不保证A在B之前执行(我还是会进行重排序优化，前提是结果正确)。</strong></p>
<p>其实我并没找到很好的例子来佐证第二点，但是要传递的思想就是程序员追求程序结果正确，而不关心内部处理器如何优化重排序。</p>
<h3 id="hanppens-before规则"><a href="#hanppens-before规则" class="headerlink" title="hanppens-before规则"></a>hanppens-before规则</h3><p>1：程序顺序规则：一个线程中的每个操作，happens-before于该线程中的任意后续操作。<br>2：监视器锁规则：对一个锁的解锁，happens-before于随后对这个锁的加锁。<br>3：volatile变量规则：对一个volatile域的写，happens-before于任意后续对这个volatile域的读。<br>4：传递性：如果A happens-before B，且B happens-before C，那么A happens-before C。<br>5：start()规则：如果线程A执行操作ThreadB.start()（启动线程B），那么A线程的 ThreadB.start()操作happens-before于线程B中的任意操作。<br>6：join()规则：如果线程A执行操作ThreadB.join()并成功返回，那么线程B中的任意操作 happens-before于线程A从ThreadB.join()操作成功返回。</p>
<h2 id="as-if-serial语义"><a href="#as-if-serial语义" class="headerlink" title="as-if-serial语义"></a>as-if-serial语义</h2><p>相较于happend-before，as-if-serial相对简单：不管怎么重排序（编译器和处理器为了提高并行度），（单线程）程序的执行结果不能被改变。编译器、runtime和处理器都必须遵守as-if-serial语义，为了遵守as-if-serial语义，编译器和处理器不会对存在数据依赖关系的操作做重排序，因为这种重排序会改变执行结果。但是，如果操作之间不存在数据依赖关系，这些操作就可能被编译器和处理器重排序</p>
<p>as-if-serial带给编写单线程程序的程序员的幻觉：我的程序是按照顺序执行，虽然有可能处理器做了优化重排序,但是最后结果是正确的。</p>
]]></content>
      <categories>
        <category>详解java并发</category>
      </categories>
      <tags>
        <tag>java并发</tag>
      </tags>
  </entry>
  <entry>
    <title>Hello World</title>
    <url>/2020/07/18/hello-world/</url>
    <content><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p>
<a id="more"></a>

<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/one-command-deployment.html" target="_blank" rel="noopener">Deployment</a></p>
]]></content>
  </entry>
  <entry>
    <title>java内存模型之volatile</title>
    <url>/2020/07/21/java%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B%E4%B9%8Bvolatile/</url>
    <content><![CDATA[<h2 id="缓存一致性"><a href="#缓存一致性" class="headerlink" title="缓存一致性"></a>缓存一致性</h2><p>看向这张图：<img src="https://upload-images.jianshu.io/upload_images/18971971-b5d0aa41f5c0ced0.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt><br>很显然当线程A,B同时对一个共享变量操作时(先操作共享变量的副本，然后再把副本刷新到主内存中)，会出现<strong>缓存一致性</strong>问题，最简单的例子就是</p>
<a id="more"></a>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">i++;</span><br></pre></td></tr></table></figure>
<p>不同线程对各自内存中的i执行i++操作，但是回写到主内存时会覆盖其它线程的操作结果，最终结果和预想不一致，这个现象称为<strong>缓存一致性</strong>，解决它主要两种方案</p>
<ul>
<li>通过在总线加LOCK#锁的方式(简单理解成某一时刻只能有一个线程操作某个共享变量更多总线锁内容可以参考#<a href="https://blog.csdn.net/qq_35642036/article/details/82801708" target="_blank" rel="noopener">总线锁</a></li>
<li>通过缓存一致性协议</li>
</ul>
<p>很明显第一种方案–总线锁采用一种独占的方式来实现的，即总线加LOCK#锁的话，只能有一个CPU能够运行，其他CPU都得阻塞，效率堪忧，第二种方案–缓存一致性协议（MESI协议）它确保每个缓存中使用的共享变量是一致的。其核心思想如下：<strong>当某个CPU在写数据时，如果发现操作的变量是共享变量，则会通知其他CPU告知该变量的缓存行是无效的，因此其他CPU在读取该变量时，发现其无效会重新从主存中加载数据。</strong></p>
<h2 id="volatile"><a href="#volatile" class="headerlink" title="volatile"></a>volatile</h2><ul>
<li>可见性：被volatile修饰的共享变量一旦被一个线程修改，会立刻同步到主内存中，并且别的线程在使用这个共享变量时会从主内存中读取，而不是本地内存</li>
<li>有序性：禁止指令重排序(JVM底层volatile是采用“内存屏障”来实现的)</li>
<li>只保证单次读写的原子性，不保证复合操作的原子性，也就是i++，即使i使用了volatile关键字修饰，也不是一个原子操作</li>
</ul>
<h3 id="volatile原理"><a href="#volatile原理" class="headerlink" title="volatile原理"></a>volatile原理</h3><h4 id="lock指令"><a href="#lock指令" class="headerlink" title="lock指令"></a>lock指令</h4><p>当修改一个volatile修饰的变量，在写回到主内存中会多出现一行汇编命令：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">lock addl $0×0,(%esp)</span><br></pre></td></tr></table></figure>
<p>这一行命令作用有三:</p>
<ul>
<li>锁总线，其它CPU对内存的读写请求都会被阻塞，直到锁释放，不过实际后来的处理器都采用锁缓存替代锁总线，因为锁总线的开销比较大，锁总线期间其他CPU没法访问内存</li>
<li>lock后的写操作会回写已修改的数据，同时让其它CPU相关缓存行失效，从而重新从主存中加载最新的数据</li>
<li>不是内存屏障却能完成类似内存屏障的功能，阻止屏障两遍的指令重排序<br>更多lock指令详解可以参考# <a href="https://www.cnblogs.com/badboys/p/12695183.html" target="_blank" rel="noopener">volatile与lock前缀指令</a></li>
</ul>
<p>那么<strong>每个处理器通过嗅探在总线上传播的数据来检查自己的缓存值是不是过期了，如果处理器发现自己缓存行对应的内存地址呗修改，就会将当前处理器的缓存行设置无效状态，会重新从系统内存中把数据库读到处理器缓存中。</strong></p>
<h4 id="volatile重排序规则"><a href="#volatile重排序规则" class="headerlink" title="volatile重排序规则"></a>volatile重排序规则</h4><table>
<thead>
<tr>
<th align="center"></th>
<th align="center">第二个操作</th>
<th align="center"></th>
<th align="center"></th>
</tr>
</thead>
<tbody><tr>
<td align="center">第一个操作</td>
<td align="center">普通读写</td>
<td align="center">volatile读</td>
<td align="center">volatile写</td>
</tr>
<tr>
<td align="center">普通读写</td>
<td align="center"></td>
<td align="center"></td>
<td align="center">NO</td>
</tr>
<tr>
<td align="center">volatiel读</td>
<td align="center">NO</td>
<td align="center">NO</td>
<td align="center">NO</td>
</tr>
<tr>
<td align="center">volatiel写</td>
<td align="center"></td>
<td align="center">No</td>
<td align="center">NO</td>
</tr>
</tbody></table>
<p>总结：</p>
<ul>
<li>当第二个操作是volatile写时，不管第一个操作是什么，都不能重排序。这个规则确保 volatile写之前的操作不会被编译器重排序到volatile写之后</li>
<li>当第一个操作是volatile读时，不管第二个操作是什么，都不能重排序。这个规则确保 volatile读之后的操作不会被编译器重排序到volatile读之前</li>
<li>当第一个操作是volatile写，第二个操作是volatile读时，不能重排序。</li>
</ul>
<h4 id="内存屏障"><a href="#内存屏障" class="headerlink" title="内存屏障"></a>内存屏障</h4><ul>
<li>在每个volatile写操作的前面插入一个StoreStore屏障</li>
<li>在每个volatile写操作的后面插入一个StoreLoad屏障</li>
<li>在每个volatile读操作的后面插入一个LoadLoad屏障</li>
<li>在每个volatile读操作的后面插入一个LoadStore屏障</li>
</ul>
<p>这是JMM在保守策略下指令序列生成，如下图：<br><img src="https://upload-images.jianshu.io/upload_images/18971971-bfe00fdad205f137.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt><br>编译器则会在字节码做一些优化，如下图：<br><img src="https://upload-images.jianshu.io/upload_images/18971971-ccab4d06f1d17716.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt></p>
<p>在优化这一阶段，不同处理器也有各自不同的松紧度，比如x86处理器，只会有最后的StoreLoad屏障(我们在前面文章也说过StoreLoad就是另外三个屏障功能的综合)，如下图：<br><img src="https://upload-images.jianshu.io/upload_images/18971971-b6c61128912b6f3c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt></p>
]]></content>
      <categories>
        <category>详解java并发</category>
      </categories>
      <tags>
        <tag>java并发</tag>
      </tags>
  </entry>
  <entry>
    <title>为什么 wait ，notify方法定义在 Object 类里面，而不是Thread中</title>
    <url>/2020/07/21/%E4%B8%BA%E4%BB%80%E4%B9%88%20wait%20%EF%BC%8Cnotify%E6%96%B9%E6%B3%95%E5%AE%9A%E4%B9%89%E5%9C%A8%20Object%20%E7%B1%BB%E9%87%8C%E9%9D%A2%EF%BC%8C%E8%80%8C%E4%B8%8D%E6%98%AFThread%E4%B8%AD/</url>
    <content><![CDATA[<p>为什么 wait ，notify方法定义在 Object 类里面，而不是Thread中。</p>
<ul>
<li>每个对象都可以上锁，所以在所有类的超类Object里面定义而不是Thread定义。</li>
<li>java的锁是基于monitor(监视器)的概念，而所有对象都是有监视器的。</li>
</ul>
<a id="more"></a>
<p>其实来讲，想要一个线程能够在某个对象上面拿到锁，释放锁，锁等待一系列操作，也就是在monitor上面有这些操作，只需要两个参数即可，线程和某个对象，那么完全可以新建一个utils类，定义一个方法wait(Thread thread,Object object)，但反过来讲，这不就是当前java的设计吗？Object是所有类的超类，wait方法定义在Object中。</p>
<p>还有两种观点也有道理:</p>
<ul>
<li>wait 和 notify 不仅仅是普通方法或同步工具，更重要的是它们是 Java 中两个线程之间的通信机制。对语言设计者而言, 如果不能通过 Java 关键字(例如 synchronized)实现通信此机制，同时又要确保这个机制对每个对象可用, 那么 Object 类则是的合理的声明位置。记住同步和等待通知是两个不同的领域，不要把它们看成是相同的或相关的。同步是提供互斥并确保 Java 类的线程安全，而 wait 和 notify 是两个线程之间的通信机制</li>
<li>在 Java 中，为了进入代码的临界区，线程需要锁定并等待锁，他们不知道哪些线程持有锁，而只是知道锁被某个线程持有， 并且需要等待以取得锁, 而不是去了解哪个线程在同步块内，并请求它们释放锁</li>
</ul>
]]></content>
      <categories>
        <category>每日一题</category>
      </categories>
  </entry>
  <entry>
    <title>java内存模型之重排序</title>
    <url>/2020/07/21/%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8BJMM/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>在了解重排序之前，你还需要知道一些基础概念知识，我在这罗列出来。</p>
<h3 id="数据依赖性"><a href="#数据依赖性" class="headerlink" title="数据依赖性"></a>数据依赖性</h3><p>如果两个操作同时访问同一个变量，只要其中有一个操作是写操作，那么这两个操作之间就存在数据依赖性。具体示例见下表:</p>
<table>
<thead>
<tr>
<th align="center">操作顺序</th>
<th align="center">代码</th>
<th align="center">解释说明</th>
</tr>
</thead>
<tbody><tr>
<td align="center">先写a再读a</td>
<td align="center">a=1;b=a</td>
<td align="center">先写a为1，再读取a的值赋给b</td>
</tr>
<tr>
<td align="center">先写a再写a</td>
<td align="center">a=1;a=2</td>
<td align="center">先写a为1，再写a为2</td>
</tr>
<tr>
<td align="center">先读b再写b</td>
<td align="center">a=b;b=1</td>
<td align="center">先写a为b，再写b为1</td>
</tr>
</tbody></table>
<p>很明显，我们可以得知上面顺序一旦交换，最后结果是有问题的，所以<strong>在重排序中，会遵守数据依赖性，重排序不会改变存在数据依赖性的两个操作的执行顺序</strong>。<br>需要注意的是<strong>数据依赖性是针对单线程</strong>而言的，多线程是不存在数据依赖性这一说，也就是重排序在多线程这一块并不遵守这个规定。</p>
<a id="more"></a>
<h3 id="java内存模型抽象概念"><a href="#java内存模型抽象概念" class="headerlink" title="java内存模型抽象概念"></a>java内存模型抽象概念</h3><p><img src="https://upload-images.jianshu.io/upload_images/18971971-f4b4c8a738c2a20f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="jmm内存模型抽象图"><br>java语言中，堆内存是多线程共享，所以图中的<strong>共享变量指的是实例域，静态域，数组元素，而不是局部变量，方法定义参数，异常处理参数</strong>。</p>
<h3 id="内存一致性"><a href="#内存一致性" class="headerlink" title="内存一致性"></a>内存一致性</h3><p>内存一致性说的是共享内存多核处理器访存序的问题，进程对某一个内存地址(和分布式的同一数据多副本的一致性有所区别)的访问序在多核下暴露出的问题，单核乱序执行重新排列无关的指令在多核系统中可能出现问题。也就是程序中 Load Store 的(ISA)顺序(冯诺依曼架构下看可以看做内存操作请求的顺序)和Load Store实际执行完成的顺序可能相同、可能不同(这取决于微体系结构的实现)，在多核情况下，程序的正确性可能出问题。有各种一致性模型来表达各种程度的相同不同，相应的有软、硬件机制来确保多核处理器上程序的正确运行</p>
<h3 id="缓存一致性"><a href="#缓存一致性" class="headerlink" title="缓存一致性"></a>缓存一致性</h3><p>//TODO</p>
<h3 id="内存屏障"><a href="#内存屏障" class="headerlink" title="内存屏障"></a>内存屏障</h3><table>
<thead>
<tr>
<th align="center">屏障类型</th>
<th align="center">示例</th>
<th align="center">解释说明</th>
</tr>
</thead>
<tbody><tr>
<td align="center">LoadLoad Barriers</td>
<td align="center">Load1;LoadLoad;Load2</td>
<td align="center">确保Load1数据的装载先于Load2及所有后续装载指令的装载</td>
</tr>
<tr>
<td align="center">StoreStore Barriers</td>
<td align="center">Stroe1;StoreStore;Store2</td>
<td align="center">确保Store1数据对其它处理器可见(刷新到内存)先于Store2及所有后续存储指令的存储</td>
</tr>
<tr>
<td align="center">LoadStore Barriers</td>
<td align="center">Load1;LoadStore;Store2</td>
<td align="center">确保Load1装载数据先于Store2及所有后续的储存指令刷新到内存</td>
</tr>
<tr>
<td align="center">StoreLoad Barriers</td>
<td align="center">Stroe1;StoreLoad;Load2</td>
<td align="center">确保Strore1数据对其它处理器可见(刷新到内存),先于Load2及所有后续存储指令的存储</td>
</tr>
</tbody></table>
<p>StoreLoad Barriers是一个“全能型”的屏障，它同时具有其他3个屏障的效果。现代的多处理器大多支持该屏障（其他类型的屏障不一定被所有处理器支持）。执行该屏障开销会很昂贵，因为当前处理器通常要把写缓冲区中的数据全部刷新到内存中（Buffer Fully Flush）。</p>
<h2 id="源码到指令的重排序"><a href="#源码到指令的重排序" class="headerlink" title="源码到指令的重排序"></a>源码到指令的重排序</h2><p><strong>编译器和处理器会对指令来做重排序，是为了提高性能。</strong><br>重排序分为以下三类：</p>
<ul>
<li><strong>编译器优化的重排序</strong>。编译器在不改变单线程程序语义的前提下(也就是不改变单线程运行结果,其实这也可以用数据依赖性来解释)，可以重新安排语句的执行顺序</li>
<li><strong>处理器指令级并行的重排序</strong>。现代处理器采用了指令级并行技术（Instruction-Level Parallelism，ILP）来将多条指令重叠执行。如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序</li>
<li><strong>内存系统的重排序</strong>。由于处理器使用缓存和读/写缓冲区，这使得加载和存储操作看上去可能是在乱序执行</li>
</ul>
<p><img src="https://upload-images.jianshu.io/upload_images/18971971-0cfc57f9372eca97.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="源码到指令之间的重排序"><br>对于<strong>编译器</strong>，JMM的编译器重排序规则会<strong>禁止特定类型的编译器重排序</strong>（不是所有的编译器重排序都要禁止）。<br>对于<strong>处理器重排序</strong>，JMM的处理器重排序规则会要求Java编译器在生成指令序列时，<strong>插入特定类型的内存屏障</strong>（Memory Barriers，Intel称之为 Memory Fence）指令，通过内存屏障指令来禁止特定类型的处理器重排序。</p>
<h2 id="重排序带来的问题"><a href="#重排序带来的问题" class="headerlink" title="重排序带来的问题"></a>重排序带来的问题</h2><table>
<thead>
<tr>
<th align="center"></th>
<th align="center">程序1</th>
<th align="center">程序2</th>
</tr>
</thead>
<tbody><tr>
<td align="center">代码</td>
<td align="center">a=1;//A1<br>x=b;//A2</td>
<td align="center">b=2;//B1<br>y=a;//B2</td>
</tr>
<tr>
<td align="center">结果</td>
<td align="center">有可能错误的结果 x=y=0</td>
<td align="center"></td>
</tr>
</tbody></table>
<p>如下图:<img src="https://upload-images.jianshu.io/upload_images/18971971-02b26121efb878ed.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="重排序带来的问题"><br>这里处理器A和处理器B可以同时把共享变量写入自己的写缓冲区（A1，B1），然后从内存中读取另一个共享变量（A2，B2），最后才把自己写缓存区中保存的脏数据刷新到内存中（A3， B3）。当以这种时序执行时，程序就可以得到x=y=0的结果</p>
<p>这段代码也可以让你更清晰的认识到重排序带来的问题</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">class ReorderExample &#123;</span><br><span class="line">    int a &#x3D; 0;</span><br><span class="line">    boolean flag &#x3D; false;</span><br><span class="line"></span><br><span class="line">    public void writer() &#123;</span><br><span class="line">        a &#x3D; 1; &#x2F;&#x2F; 1</span><br><span class="line">        flag &#x3D; true; &#x2F;&#x2F; 2</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    Public void reader() &#123;</span><br><span class="line">        if (flag) &#123; &#x2F;&#x2F; 3</span><br><span class="line">            int i &#x3D; a * a; &#x2F;&#x2F; 4</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这段代码在多线程运行环境下可能的时序图有以下:<br><img src="https://upload-images.jianshu.io/upload_images/18971971-8956f30f35f55995.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="程序执行时序图1"><br><img src="https://upload-images.jianshu.io/upload_images/18971971-464e0086ea0914d4.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="程序执行时序图2"></p>
<p>通过这两张图我想已经很清晰的向你展示了重排序在多线程环境下给程序带来的不可控的结果,需要再次重申一次的是<strong>单线程下操作之间存在数据依赖性，不会重排序，但是多线程下，比如线程A的flag = true和线程B的if(flag) 并不存在数据依赖性</strong>,所以重排序在多线程下会发现，最后带来的就是程序结果和预期的不一样。</p>
]]></content>
      <categories>
        <category>详解java并发</category>
      </categories>
      <tags>
        <tag>java并发</tag>
      </tags>
  </entry>
  <entry>
    <title>java并发之Synchronized</title>
    <url>/2020/07/23/java%E5%B9%B6%E5%8F%91%E4%B9%8BSynchronized/</url>
    <content><![CDATA[<h3 id="synchronized的特性"><a href="#synchronized的特性" class="headerlink" title="synchronized的特性"></a>synchronized的特性</h3><ul>
<li>原子性：原子是世界上的最小单位，具有不可分割性。比如 a=0；（a非long和double类型） 这个操作是不可分割的，那么我们说这个操作时原子操作。再比如：a++； 这个操作实际是a = a + 1，它不是一个原子操作，它是可分割的，它也有并发问题，即使你加上了volatile关键字，这一点跟volatile不同。</li>
<li>可见性：是指线程之间的可见性，一个线程修改的状态对另一个线程是可见的。也就是一个线程修改的结果。另一个线程马上就能看到。</li>
<li>有序性：即程序执行的顺序按照代码的先后顺序执行，为什么这么说了，因为jvm还会对输入代码进行乱序执行(out-of-order Execution)优化，处理器会在计算之后将乱序执行的结果重组，也就是java虚拟机的即时编译器中也有指令重排序优化。</li>
<li>可重入性：synchronized和ReentrantLock都是可重入锁。当一个线程试图操作一个由其他线程持有的对象锁的临界资源时，将会处于阻塞状态，但当一个线程再次请求自己持有对象锁的临界资源时，这种情况属于重入锁。可重入最大的作用是避免死锁，如：子类同步方法调用了父类同步方法，如没有可重入的特性，则会发生死锁；<a id="more"></a>
<h3 id="synchronized的用法："><a href="#synchronized的用法：" class="headerlink" title="synchronized的用法："></a>synchronized的用法：</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public class SynchronizedTest &#123;</span><br><span class="line"></span><br><span class="line">    public Object object &#x3D; new Object();</span><br><span class="line">    &#x2F;&#x2F;成员函数加锁，需要获得当前类实例对象的锁</span><br><span class="line">    public synchronized void add()&#123;</span><br><span class="line">        &#x2F;&#x2F;TODO</span><br><span class="line">    &#125;</span><br><span class="line">    &#x2F;&#x2F; 静态方法加锁，需要获得当前类的锁</span><br><span class="line">    public synchronized static void add1()&#123;</span><br><span class="line">        &#x2F;&#x2F;TODO</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public void method()&#123;</span><br><span class="line">        &#x2F;&#x2F;需要获取SynchronizedTest类的锁</span><br><span class="line">        synchronized (SynchronizedTest.class)&#123;</span><br><span class="line">            &#x2F;&#x2F;TODO</span><br><span class="line">        &#125;</span><br><span class="line">        &#x2F;&#x2F;需要获取object实例对象的锁</span><br><span class="line">        synchronized (object)&#123;</span><br><span class="line">            &#x2F;&#x2F;TODO</span><br><span class="line">        &#125;</span><br><span class="line">        &#x2F;&#x2F;需要获取当前类实例对象的锁</span><br><span class="line">        synchronized (this)&#123;</span><br><span class="line">            &#x2F;&#x2F;TODO</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="synchronized锁的实现"><a href="#synchronized锁的实现" class="headerlink" title="synchronized锁的实现"></a>synchronized锁的实现</h3>前面也写了synchronized有两种形式上锁，对方法上锁和代码块。他们都是在进入同步代码之前先获取锁，获取到锁之后锁的计数器+1，同步代码执行完锁的计数器-1，如果获取失败就阻塞式等待锁的释放。只是他们在同步块识别方式上有所不一样，从class字节码文件可以表现出来，一个是通过方法flags标志，一个是monitorenter和monitorexit指令操作。<br>查看反编译<br><img src="https://upload-images.jianshu.io/upload_images/18971971-de64aba82b28b24b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="synchronized同步代码块原理实现"><br>需要注意的是有不止一个monitorexit呢？其实后面的monitorexit是来处理异常的，仔细看反编译的字节码，正常情况下第一个monitorexit之后会执行goto指令，也就是return语句，也就是说正常情况下只会执行第一个monitorexit释放锁，然后返回。而如果在执行中发生了异常，后面的monitorexit就起作用了，它是由编译器自动生成的，在发生异常时处理异常然后释放掉锁。</li>
</ul>
<p>因为在synchronized同步方法我没找到flags里面多了一个ACC_SYNCHRONIZED标志，这标志用来告诉JVM这是一个同步方法，在进入该方法之前先获取相应的锁，锁的计数器加1，方法结束后计数器-1，如果获取失败就阻塞住，知道该锁被释放。所以这一块 先放着，后续再加上来。</p>
<p>因此我们可以总结：</p>
<ul>
<li>同步代码块：monitorenter指令插入到同步代码块的开始位置，monitorexit指令插入到同步代码块的结束位置，JVM需要保证每一个monitorenter都有一个monitorexit与之相对应。任何对象都有一个monitor与之相关联，当且一个monitor被持有之后，他将处于锁定状态。线程执行到monitorenter指令时，将会尝试获取对象所对应的monitor所有权，即尝试获取对象的锁；</li>
<li>同步方法：synchronized方法则会被翻译成普通的方法调用和返回指令如:invokevirtual、areturn指令，在JVM字节码层面并没有任何特别的指令来实现被synchronized修饰的方法，而是在Class文件的方法表中将该方法的access_flags字段中的synchronized标志位置1，表示该方法是同步方法并使用调用该方法的对象或该方法所属的Class在JVM的内部对象表示Klass做为锁对象。<br>更多细节可以参考# <a href="https://www.cnblogs.com/javaminer/p/3889023.html" target="_blank" rel="noopener">这里</a></li>
</ul>
<p>下面这些部分来自《深入理解java虚拟机》</p>
<h3 id="synchronized实现锁的基础"><a href="#synchronized实现锁的基础" class="headerlink" title="synchronized实现锁的基础"></a>synchronized实现锁的基础</h3><p>首先一个对象可以分为以下部分：<br><img src="https://upload-images.jianshu.io/upload_images/18971971-b1f7b04c8028d3a9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="对象储存布局"></p>
<ul>
<li>实例数据：存放类的属性数据信息，包括父类的属性信息；</li>
<li>对齐填充：由于虚拟机要求 对象起始地址必须是8字节的整数倍。填充数据不是必须存在的，仅仅是为了字节对齐；</li>
<li>对象头：这部分拉出来单说。<h4 id="对象头"><a href="#对象头" class="headerlink" title="对象头"></a>对象头</h4>对象头分为两部分：</li>
<li>Mark Word:用于储存对象自身的运行时数据，比如哈希码，GC分代年龄，这部分数据在32位和64位的虚拟机中分别为32bit和64bit，是实现轻量级锁和偏向锁的关键。</li>
<li>Class Metadata Address：这部分用于存储指向方法区对象数据类型的指针，如果是数组对象的话，还有一个额外的部分用于存储数组长度。</li>
</ul>
<p>对象头信息是与对象自身定义的数据无关的额外存储成本，但是考虑到虚拟机的空间效率，Mark Word被设计成一个非固定的数据结构以便在极小的空间内存存储尽量多的数据，它会根据对象的状态复用自己的存储空间，也就是说，Mark Word会随着程序的运行发生变化，同时前面也说过在32bit和64bit上Mark Word储存结构也不太一样：</p>
<ul>
<li>32bit<br><img src="https://upload-images.jianshu.io/upload_images/18971971-2484703d007fabfa.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="32bit无锁"></li>
</ul>
<p><img src="https://upload-images.jianshu.io/upload_images/18971971-1ec552a27baebf7a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="32bit有锁.png"><br>关于锁标志位这部分结合这张图来看：<br><img src="https://upload-images.jianshu.io/upload_images/18971971-4818e267be0f759a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="Mark Word"></p>
<ul>
<li>64bit<br><img src="https://upload-images.jianshu.io/upload_images/18971971-b4235cd57b26a5ec.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="64bit有锁和无锁"></li>
</ul>
<p>除了对象头外，synchronized实现细节还包括monitor</p>
<h4 id="monitor"><a href="#monitor" class="headerlink" title="monitor"></a>monitor</h4><p>更多monitor细节可以参考# <a href="https://www.cnblogs.com/javaminer/p/3889023.html" target="_blank" rel="noopener">这里</a></p>
<h3 id="jvm对锁的优化"><a href="#jvm对锁的优化" class="headerlink" title="jvm对锁的优化"></a>jvm对锁的优化</h3><h4 id="自旋锁和自适应性自旋锁"><a href="#自旋锁和自适应性自旋锁" class="headerlink" title="自旋锁和自适应性自旋锁"></a>自旋锁和自适应性自旋锁</h4><ul>
<li><p>自旋锁：出现背景是因为挂起线程和恢复线程改的操作需要转入内核态中完成，这明显不是一个好选择，所以可以让后面那个线程“稍等一下”，但是不放弃cpu时间，请注意，自旋锁是占用cpu时间的，只是减少了线程状态切换的消耗，如果说一直在那等肯定会极大浪费cpu性能，所以自旋次数试试10次，可以使用-XX:PreBlockSpin来更改。</p>
</li>
<li><p>自适应性自旋锁：jdk1.6引入自适应性自旋锁，意味着自旋时间不再固定，而是由前一次在同一个锁上的自旋时间及锁的拥有者的转态来决定，例如线程如果自旋成功了，那么下次自旋的次数会增多，因为JVM认为既然上次成功了，那么这次自旋也很有可能成功，那么它会允许自旋的次数更多。反之，如果对于某个锁，自旋很少成功，那么在以后获取这个锁的时候，自旋的次数会变少甚至忽略，避免浪费处理器资源。有了自适应性自旋，随着程序运行和性能监控信息的不断完善，JVM对程序锁的状况预测就会变得越来越准确，JVM也就变得越来越聪明。</p>
<h4 id="锁消除"><a href="#锁消除" class="headerlink" title="锁消除"></a>锁消除</h4><p>锁消除是指虚拟机即时编译器在运行时，对一些代码上要求同步，但是被检测到不可能存在共享数据竞争的锁进行消除。<br>在《深入理解java虚拟机》一文中这样举得例子：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public String concatString(String str1,String str2,String str3)&#123;</span><br><span class="line">    return str1+str2+str3;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>String是一个不可变的类，在jdk1.5之前，这段代码会转为stringBuffer对象的连续append(),在jdk1.5之后，会转为StringBuilder对象的连续append()操作，因为stringBuffer.append()都有一个同步代码块，而这段代码很明显并不会出现并发问题，所以虽然这里有锁，但是在即时编译后会被安全消除掉。</p>
<h4 id="锁粗化："><a href="#锁粗化：" class="headerlink" title="锁粗化："></a>锁粗化：</h4><p>如果一些列的连续操作都是对同一个对象反复加锁和解锁，即时没有没有线程竞争，频繁的进行互斥同步操作也会导致不必要的性能损耗。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public String concatString2(String str1,String str2,String str3)&#123;</span><br><span class="line">    StringBuffer sb &#x3D; new StringBuffer();</span><br><span class="line">    sb.append(str1);</span><br><span class="line">    sb.append(str2);</span><br><span class="line">    sb.append(str3);</span><br><span class="line">    return sb.toString();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>前面说过stringBuffer.append()都有一个同步代码块，这种情况下如果虚拟机检测到有这样一串零碎的操作都是对用一个对象加锁，将会把加锁同步的范围拓展（粗化）到整个操作序列的外部，也就是上面这段代码只加锁一次。</p>
<h4 id="轻量级锁"><a href="#轻量级锁" class="headerlink" title="轻量级锁"></a>轻量级锁</h4><h5 id="加锁过程："><a href="#加锁过程：" class="headerlink" title="加锁过程："></a>加锁过程：</h5></li>
<li><p>代码进入同步块的时候，如果同步对象锁状态为无锁状态(锁标志位为”01”状态，是否为偏向锁为”0”)，虚拟机首先将在当前线程的栈帧中建立一个名为锁记录(Lock Recored)的空间，用于储存锁对象目前的Mark Word的拷贝(官方把这份拷贝加了个Displaced前缀，即Displaced Mark Word)。此时线程堆栈和对象头的状态如下：<br><img src="https://upload-images.jianshu.io/upload_images/18971971-de3c1d7a904e947e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="轻量级锁cas操作前堆栈和对象的状态"></p>
</li>
<li><p>将对象头的Mark Word拷贝到线程的锁记录(Lock Recored)中。</p>
</li>
<li><p>虚拟机将使用CAS操作尝试将对象的Mark Word更新为指向Lock Record的指针。如果这个更新成功了，这个线程就拥有了该对象的锁，并且对象Mark Word的锁标志位将转变为”00”，即表示此对象处于轻量级锁的状态。这时线程堆栈和对象头的状态如下：<br><img src="https://upload-images.jianshu.io/upload_images/18971971-1a02d50e6f53f4c0.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="轻量级锁cas操作后堆栈和对象的状态"></p>
</li>
<li><p>如果更新失败，虚拟机首先会检查对象的Mark Word是否指向当前线程的栈帧，如果是就说明当前线程已经拥有了这个对象的锁，可以直接进入同步块继续执行，否则说明这个锁对象已经被其其它线程抢占了。如果多个线程竞争锁，进入自旋执行上一步，自旋结束后仍未获得锁，轻量级锁就需要膨胀为重量级锁，锁标志位状态值变为”10”，Mark Word中储存就是指向重量级的指针，当前线程以及后面等待锁的线程也要进入阻塞状态。</p>
<h5 id="释放锁的过程："><a href="#释放锁的过程：" class="headerlink" title="释放锁的过程："></a>释放锁的过程：</h5></li>
<li><p>使用CAS操作将对象当前的Mark Word和线程中复制的Displaced Mark Word替换回来(依据Mark Word中锁记录指针是否还指向本线程的锁记录)。</p>
</li>
<li><p>如果替换成功，整个同步过程就完成了，恢复到无锁的状态(01)。</p>
</li>
<li><p>如果替换失败，说明有其他线程尝试获取该锁(此时锁已膨胀)，那就要在释放锁的同时，唤醒被挂起的线程。</p>
</li>
</ul>
<h4 id="偏向锁"><a href="#偏向锁" class="headerlink" title="偏向锁"></a>偏向锁</h4><p>目的是消除数据在无竞争情况下的同步原语，进一步提高程序的运行性能。如果说轻量级锁是在无竞争的情况下使用CAS操作区消除同步使用的互斥量，那么偏向锁就是在无竞争的情况下把整个同步都消除掉，连CAS操作都不用做了。偏向锁默认是开启的，也可以关闭。<br>偏向锁”偏”，就是”偏心”的”偏”，它的意思是这个锁会偏向于第一个获得它的程序，如果在接下来的执行过程中，该锁没有被其他的线程获取，则持有偏向锁的线程将永远不需要再进行同步。</p>
<h5 id="获取锁的过程："><a href="#获取锁的过程：" class="headerlink" title="获取锁的过程："></a>获取锁的过程：</h5><ul>
<li>当锁第一次被线程尝试获取的时候，虚拟机会把对象头中的标志位设为”01”,也就是偏向模式，同时使用cas操作吧获取到这个锁的线程id记录在对象的mark word中，如果cas设置成功，持有偏向锁的线程以后每次进入这个锁相关的同步块时都不需要进行任何同步操作。</li>
<li>当有另外一个线程尝试获取这个锁时，偏向模式就结束了，检查Mark Word是否为可偏向锁的状态，即是否偏向锁即为1即表示支持可偏向锁，否则为0表示不支持可偏向锁。如果是可偏向锁，则检查Mark Word储存的线程ID是否为当前线程ID，如果是则执行同步块，否则通过CAS操作去修改线程ID修改成本线程的ID，如果修改成功则执行同步代码块，否则挂起这个线程，升级为轻量级锁。<br>也就是根据锁对象是否处于被锁定的状态，撤销偏向后到未锁定（标志位为01）或轻量级锁（标志位为00）的状态。<br>偏向锁和轻量级锁的状态转化和对象Mark Word的关系如下：<br><img src="https://upload-images.jianshu.io/upload_images/18971971-d225aefce306ca1a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="偏向锁和轻量级锁的状态转化和对象Mark Word"><h5 id="锁释放"><a href="#锁释放" class="headerlink" title="锁释放"></a>锁释放</h5></li>
<li>1：有其他线程来获取这个锁，偏向锁的释放采用了一种只有竞争才会释放锁的机制，线程是不会主动去释放偏向锁，需要等待其他线程来竞争。</li>
<li>:2：等待全局安全点(在这个是时间点上没有字节码正在执行)。</li>
<li>:3：暂停拥有偏向锁的线程，检查持有偏向锁的线程是否活着，如果不处于活动状态，则将对象头设置为无锁状态，否则设置为被锁定状态。如果锁对象处于无锁状态，则恢复到无锁状态(01)，以允许其他线程竞争，如果锁对象处于锁定状态，则挂起持有偏向锁的线程，并将对象头Mark Word的锁记录指针改成当前线程的锁记录，锁升级为轻量级锁状态(00)。<h4 id="重量级锁"><a href="#重量级锁" class="headerlink" title="重量级锁"></a>重量级锁</h4>Synchronized是通过对象内部的一个叫做 监视器锁（Monitor）来实现的。但是监视器锁本质又是依赖于底层的操作系统的Mutex Lock来实现的。而操作系统实现线程之间的切换这就需要从用户态转换到核心态，这个成本非常高，状态之间的转换需要相对比较长的时间，这就是为什么Synchronized效率低的原因。因此，这种依赖于操作系统Mutex Lock所实现的锁我们称之为 “重量级锁”。</li>
</ul>
<p>关于synchronized更多细节参考#<a href="https://blog.csdn.net/u012465296/article/details/53022317" target="_blank" rel="noopener">这里</a></p>
]]></content>
      <categories>
        <category>详解java并发</category>
      </categories>
      <tags>
        <tag>java并发</tag>
      </tags>
  </entry>
</search>
